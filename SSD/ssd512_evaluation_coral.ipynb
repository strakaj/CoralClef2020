{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from scipy.misc import imread\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from models.keras_ssd512 import ssd_512\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from eval_utils.average_precision_evaluator import Evaluator\n",
    "\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "import copy\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 512\n",
    "img_width = 512\n",
    "n_classes = 13\n",
    "model_mode = 'inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\DOMA\\Dropbox\\FAV_3_2\\BP\\_GITHUB\\SSD\\keras_layers\\keras_layer_DecodeDetections.py:174: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\DOMA\\Dropbox\\FAV_3_2\\BP\\_GITHUB\\SSD\\keras_loss_function\\keras_ssd_loss.py:166: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() \n",
    "\n",
    "#nastaveni modelu a nacteni vah\n",
    "model = ssd_512(image_size=(img_height, img_width, 3),\n",
    "                n_classes=n_classes,\n",
    "                mode=model_mode,\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05], # The scales for MS COCO are [0.04, 0.1, 0.26, 0.42, 0.58, 0.74, 0.9, 1.06]\n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "               two_boxes_for_ar1=True,\n",
    "               steps=[8, 16, 32, 64, 128, 256, 512],\n",
    "               offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "               clip_boxes=False,\n",
    "               variances=[0.1, 0.1, 0.2, 0.2],\n",
    "               normalize_coords=True,\n",
    "               subtract_mean=[123, 117, 104],\n",
    "               swap_channels=[2, 1, 0],\n",
    "               confidence_thresh=0.5,\n",
    "               iou_threshold=0.45,\n",
    "               top_k=200,\n",
    "               nms_max_output_size=400)\n",
    "\n",
    "\n",
    "\n",
    "weights_path = 'training_summaries/ssd512/ssd512_coralclef2020_epoch-200.h5'\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 'train_annot.json': 100%|██████████████████████████████████████████████| 371/371 [00:00<00:00, 23167.09it/s]\n",
      "Processing 'validation_annot.json': 100%|███████████████████████████████████████████| 69/69 [00:00<00:00, 13787.85it/s]\n",
      "Trenovaci mnozina:\t   371\n",
      "Validacni mnozina:\t    69\n"
     ]
    }
   ],
   "source": [
    "# nacteni obrazku a anotaci\n",
    "train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path = None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path = None)\n",
    "\n",
    "\n",
    "\n",
    "CoralClef_2020_images_dir      = '../CoralClef2020/training_set_2020/'\n",
    "\n",
    "\n",
    "CoralClef_2020_annotations_train      =  '../CoralClef2020/annotations/train_annot.json'\n",
    "CoralClef_2020_annotations_val        =  '../CoralClef2020/annotations/validation_annot.json'\n",
    "\n",
    "\n",
    "\n",
    "classes = ['c_hard_coral_branching', 'c_hard_coral_submassive', 'c_hard_coral_boulder',\n",
    "           'c_hard_coral_encrusting', 'c_hard_coral_table', 'c_hard_coral_foliose', 'c_hard_coral_mushroom',\n",
    "           'c_soft_coral', 'c_soft_coral_gorgonian', 'c_sponge', 'c_sponge_barrel', 'c_fire_coral_millepora',\n",
    "           'c_algae_macro_or_leaves']\n",
    "\n",
    "\n",
    "train_dataset.parse_json(images_dirs=[CoralClef_2020_images_dir],\n",
    "                         annotations_filenames=[CoralClef_2020_annotations_train],\n",
    "                         ground_truth_available=True,\n",
    "                         include_classes='all',\n",
    "                         verbose = True,\n",
    "                         ret=True\n",
    "                        )\n",
    "\n",
    "val_dataset.parse_json(images_dirs=[CoralClef_2020_images_dir],\n",
    "                       annotations_filenames=[CoralClef_2020_annotations_val],\n",
    "                       ground_truth_available=True,\n",
    "                       include_classes='all',\n",
    "                       verbose = True,\n",
    "                       ret=True\n",
    "                      )\n",
    "\n",
    "\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Trenovaci mnozina:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Validacni mnozina:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../mAP/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/69 [============================>.] - ETA:  - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA: 0s"
     ]
    }
   ],
   "source": [
    "dataset = val_dataset\n",
    "\n",
    "\n",
    "progbar = tf.keras.utils.Progbar(dataset.get_dataset_size())\n",
    "k = 0\n",
    "\n",
    "image_ids = list(range(dataset.get_dataset_size()))\n",
    "\n",
    "for ind in image_ids:\n",
    "    progbar.update(k)\n",
    "    ground_truth_file = list()\n",
    "    detection_file = list()\n",
    "    # nacteni obrazku a anotaci\n",
    "    original_labels = dataset.labels[ind]\n",
    "    file_names = dataset.filenames[ind]\n",
    "             \n",
    "    img = np.array(Image.open(file_names), dtype=np.uint8) \n",
    "    img2, labels  = resize(img, original_labels)\n",
    "    images = img2.reshape([1,512,512,3])\n",
    "    labels = [np.array(labels)]\n",
    "\n",
    "\n",
    "    # detekce\n",
    "    y_pred = model.predict(images)\n",
    "    confidence_threshold = 0.5\n",
    "    y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
    "    \n",
    "    \n",
    "    # prevedeni detekovanych a graund truth dat do pozadovaneho formatu\n",
    "    for box in y_pred_thresh[0]:\n",
    "        class_id = box[0]\n",
    "        confidence = box[1]\n",
    "        xmin = box[2]\n",
    "        ymin = box[3]\n",
    "        xmax = box[4]\n",
    "        ymax = box[5]\n",
    "        label = classes[int(class_id)-1]\n",
    "        detection_file.append((str(classes[int(class_id)-1]) +' '+ str(confidence) +' '+ str(xmin) +' '+ str(ymin) +' '+ str(xmax) +' '+ str(ymax)))\n",
    "        \n",
    "        \n",
    "    for box in labels[0]:\n",
    "        class_id = box[0]\n",
    "        xmin = box[1]\n",
    "        ymin = box[2]\n",
    "        xmax = box[3]\n",
    "        ymax = box[4]\n",
    "        label = classes[int(class_id)-1]\n",
    "        ground_truth_file.append((str(classes[int(class_id)-1]) +' '+ str(xmin) +' '+ str(ymin) +' '+ str(xmax) +' '+ str(ymax)))\n",
    "    \n",
    "    \n",
    "    # ulozeni souboru pro kazdy obrazek zvlast\n",
    "    with open(OUTPUT_PATH + '/ground-truth/img_{}.txt'.format(ind),'w') as f:\n",
    "          f.write('\\n'.join(ground_truth_file))\n",
    "            \n",
    "    with open(OUTPUT_PATH + '/detection-results/img_{}.txt'.format(ind),'w') as f:\n",
    "          f.write('\\n'.join(detection_file))\n",
    "            \n",
    "    k = k + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
