{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from matplotlib.patches import Rectangle\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "import samples.coco.coco as coco\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.utils import extract_bboxes\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# cesta pro ulozeni vysledku\n",
    "MODEL_DIR = 'training_summaries/'\n",
    "# cesta k natrenovanemu modelu\n",
    "MODEL_PATH = \"training_summaries/mask_rcnn_coralclef2020_epoch-083.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                26\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    14\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 13 + 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "# CoralClef 2020 jmena trid\n",
    "class_names = ['BG','c_hard_coral_branching', 'c_hard_coral_submassive', 'c_hard_coral_boulder',\n",
    "               'c_hard_coral_encrusting', 'c_hard_coral_table', 'c_hard_coral_foliose', 'c_hard_coral_mushroom',\n",
    "               'c_soft_coral', 'c_soft_coral_gorgonian', 'c_sponge', 'c_sponge_barrel', 'c_fire_coral_millepora',\n",
    "               'c_algae_macro_or_leaves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\DOMA\\Dropbox\\FAV_3_2\\BP\\_GITHUB\\Mask_RCNN\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# vytvoreni modelu v modu inference\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# nacteni natrenovaneho modelu\n",
    "model.load_weights(MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cesta k datasetu a anotac√≠m\n",
    "DATASET_DIR = \"../CoralClef2020/training_set_2020/\"\n",
    "ANNOTATION_TRAIN = '../CoralClef2020/annotations/train_annot.json'\n",
    "ANNOTATION_VAL =  '../CoralClef2020/annotations/validation_annot.json'\n",
    "OUTPUT_PATH = '../mAP/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trida pro nacteni datasetu\n",
    "class CoralDataset(Dataset):\n",
    "    \n",
    "    # nacteni obrazku\n",
    "    def load_dataset(self, is_train=True):\n",
    "\n",
    "        # pridani trid do datasetu\n",
    "        for i in range(1,len(class_names)):\n",
    "            self.add_class(\"dataset\", i, class_names[i])\n",
    "        \n",
    "        # nastaveni cesty k souboru s anotacemi\n",
    "        if(is_train):\n",
    "            annotation_path = ANNOTATION_TRAIN\n",
    "        else:\n",
    "            annotation_path = ANNOTATION_VAL\n",
    "            \n",
    "        with open(annotation_path) as json_file:\n",
    "            data = json.load(json_file)\n",
    "        \n",
    "        # nacteni anotaci a vlozeni obrazku do datasetu\n",
    "        for annot in data['images']:\n",
    "            image_id = annot['id']\n",
    "            img_path = DATASET_DIR + annot['file_name']\n",
    "            ann_path = annotation_path\n",
    "\n",
    "            self.add_image('dataset', \n",
    "                           image_id=image_id, \n",
    "                           width=annot['width'], height=annot['height'],\n",
    "                           path=img_path, \n",
    "                           annotation=ann_path)\n",
    "            \n",
    "\n",
    "\n",
    "    # nacteni masek\n",
    "    def load_mask(self, image_id):\n",
    "        # nacteni informaci o obrazku\n",
    "        info = self.image_info[image_id]\n",
    "\n",
    "        # nacteni anotaci\n",
    "        path = info['annotation']\n",
    "        with open(path) as json_file:\n",
    "            data = json.load(json_file)\n",
    "        \n",
    "        segments = []\n",
    "        class_ids = []\n",
    "        for s in data['annotations']:\n",
    "            if(s['image_id'] == info['id']):\n",
    "                segments.append(s['segmentation'])\n",
    "                class_ids.append(s['category_id'] + 1)\n",
    "            \n",
    "        # vytvoreni 2d pole pro kazdou masku\n",
    "        masks = zeros([info['height'], info['width'], len(segments)], dtype='uint8')\n",
    "        for i in range(len(segments)):\n",
    "            r = []\n",
    "            c = []\n",
    "            for s0,s1 in zip(segments[i][0::2], segments[i][1::2]):\n",
    "                r.append(int(s1))\n",
    "                c.append(int(s0))\n",
    "            r = np.array(r)\n",
    "            c = np.array(c)\n",
    "            rr, cc = skimage.draw.polygon(r, c)\n",
    "            masks[rr, cc, i] = 1\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    " \n",
    "    # nacteni informaci o obrazku\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trenovaci: 371\n",
      "Validacni: 69\n"
     ]
    }
   ],
   "source": [
    "# nacteni trenovaci mnoziny\n",
    "train_set = CoralDataset()\n",
    "train_set.load_dataset(is_train=True)\n",
    "train_set.prepare()\n",
    "print('Trenovaci: %d' % len(train_set.image_ids))\n",
    "\n",
    "# nacteni validacni mnoziny\n",
    "val_set = CoralDataset()\n",
    "val_set.load_dataset(is_train=False)\n",
    "val_set.prepare()\n",
    "print('Validacni: %d' % len(val_set.image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/69 [============================>.] - ETA: 4s"
     ]
    }
   ],
   "source": [
    "dataset = val_set\n",
    "\n",
    "\n",
    "image_ids = dataset.image_ids\n",
    "\n",
    "progbar = tf.keras.utils.Progbar(len(image_ids))\n",
    "k = 0\n",
    "\n",
    "for image_id in image_ids:\n",
    "    progbar.update(k)\n",
    "    detection_file = []\n",
    "    ground_truth_file = []\n",
    "    \n",
    "    # nacteni graund truth dat\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, config, \n",
    "                                                                              image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, config), 0)\n",
    "    \n",
    "    # detekce\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    \n",
    "    # prevedeni dat do pozadovaneho formatu\n",
    "    for i in range(len(gt_class_id)):\n",
    "        ground_truth_file.append(str(class_names[gt_class_id[i]]) +' '+ str(gt_bbox[i][0]) +' '+ str(gt_bbox[i][1]) +' '+ str(gt_bbox[i][2]) +' '+ str(gt_bbox[i][3]))\n",
    "    \n",
    "    for i in range(len(r[\"class_ids\"])):\n",
    "        detection_file.append((str(class_names[r[\"class_ids\"][i]]) +' '+ str(r[\"scores\"][i]) +' '+ str(r[\"rois\"][i][0]) +' '+ str(r[\"rois\"][i][1]) +' '+ str(r[\"rois\"][i][2]) +' '+ str(r[\"rois\"][i][3])))\n",
    "    \n",
    "\n",
    "    # ulozeni souboru, pro kazdy obrazek zvlast\n",
    "    with open(OUTPUT_PATH + '/ground-truth/img_{}.txt'.format(image_id),'w') as f:\n",
    "          f.write('\\n'.join(ground_truth_file))\n",
    "            \n",
    "    with open(OUTPUT_PATH + '/detection-results/img_{}.txt'.format(image_id),'w') as f:\n",
    "          f.write('\\n'.join(detection_file))\n",
    "            \n",
    "    k = k + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
